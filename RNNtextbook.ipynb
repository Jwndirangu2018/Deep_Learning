{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6Wc7PGSMEt6f+ycrFLPPl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Implementing RNN from scratch"],"metadata":{"id":"3f0moQelwI2d"}},{"cell_type":"code","source":["!pip install matplotlib-venn"],"metadata":{"id":"-cnU209aw9V6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install d2l"],"metadata":{"id":"gPyfCV_fyBaw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySyUG3XWwHum"},"outputs":[],"source":["%matplotlib inline\n","import math\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from d2l import torch as d2l"]},{"cell_type":"markdown","source":["We begin by defining a class to implement the RNN model (Section 9.4.2). Note that the number of hidden units num_hiddens is a tunable hyperparameter."],"metadata":{"id":"oERV_ZmFwSiQ"}},{"cell_type":"code","source":["class RNNScratch(d2l.Module):  #@save\n","    \"\"\"The RNN model implemented from scratch.\"\"\"\n","    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.W_xh = nn.Parameter(\n","            torch.randn(num_inputs, num_hiddens) * sigma)\n","        self.W_hh = nn.Parameter(\n","            torch.randn(num_hiddens, num_hiddens) * sigma)\n","        self.b_h = nn.Parameter(torch.zeros(num_hiddens))"],"metadata":{"cellView":"code","id":"6ZoHn_3gzXTE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@d2l.add_to_class(RNNScratch)  #@save\n","def forward(self, inputs, state=None):\n","    if state is None:\n","        # Initial state with shape: (batch_size, num_hiddens)\n","        state = torch.zeros((inputs.shape[1], self.num_hiddens),\n","                          device=inputs.device)\n","    else:\n","        state, = state\n","    outputs = []\n","    for X in inputs:  # Shape of inputs: (num_steps, batch_size, num_inputs)\n","        state = torch.tanh(torch.matmul(X, self.W_xh) +\n","                         torch.matmul(state, self.W_hh) + self.b_h)\n","        outputs.append(state)\n","    return outputs, state"],"metadata":{"cellView":"code","id":"jrQj9lkTz_hg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can feed a minibatch of input sequences into an RNN model as follows."],"metadata":{"id":"6yNATz_f0Ljq"}},{"cell_type":"code","source":["batch_size, num_inputs, num_hiddens, num_steps = 2, 16, 32, 100\n","rnn = RNNScratch(num_inputs, num_hiddens)\n","X = torch.ones((num_steps, batch_size, num_inputs))\n","outputs, state = rnn(X)"],"metadata":{"id":"Lrcl72C80PHr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Letâ€™s check whether the RNN model produces results of the correct shapes to ensure that the dimensionality of the hidden state remains unchanged"],"metadata":{"id":"zPTQtfH80byw"}},{"cell_type":"code","source":["def check_len(a, n):  #@save\n","    \"\"\"Check the length of a list.\"\"\"\n","    assert len(a) == n, f'list\\'s length {len(a)} != expected length {n}'\n","\n","def check_shape(a, shape):  #@save\n","    \"\"\"Check the shape of a tensor.\"\"\"\n","    assert a.shape == shape, \\\n","            f'tensor\\'s shape {a.shape} != expected shape {shape}'\n","\n","check_len(outputs, num_steps)\n","check_shape(outputs[0], (batch_size, num_hiddens))\n","check_shape(state, (batch_size, num_hiddens))"],"metadata":{"cellView":"code","id":"aFrQH-8G0rGO"},"execution_count":null,"outputs":[]}]}